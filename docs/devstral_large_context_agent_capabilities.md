# Devstral: Openâ€‘Source Agentic Model Tailored for Software Engineering

* **Date**: 16.07.25  
* **Note**: Information in this article is summarized by GPTâ€‘4o

---

### ğŸ§  1. Context Window & Longâ€‘Context Handling  
- **Devstral** inherits a **128â€¯Kâ€‘token** context window from Mistral Small 3.1.  
- Available in 14â€¯GB (approx. 24â€¯B parameters) and 24â€¯B variants, all supporting extended reasoning over large codebases or multi-file projects.

â¡ï¸ **Conclusion:** Devstral natively handles massive context, ideal for deep code analysis and extended agentic pipelines.

---

### ğŸ”§ 2. Tools & Chainâ€‘ofâ€‘Thought (CoT) / Agent Capabilities  
- Specifically **designed for agentic coding**, built with the OpenHands scaffoldâ€”enabling functions like `search_repo()`, `edit_file()`, and `run_tests()` out of the box.  
- Used in frameworks like OpenHands, Ollama, Goose, and Continueâ€”automating code exploration, edits, and test validation.  
- Some community reports (e.g., DEV Community) note occasional tool hallucinations, but overall itâ€™s recognized as a leading agentic open model.

â¡ï¸ **Conclusion:** Devstral is tailored for automated code tasks and tool orchestration, though environment setup may affect stability.

---

### ğŸ¯ 3. CoT Reasoning & Benchmark Performance  
- Achieves **46.8â€¯% on SWEâ€‘Bench Verified**, ranking as the top openâ€‘source modelâ€”beating GPTâ€‘4.1â€‘mini by 23 points.  
- A June 10 update (Devstral Smallâ€¯1.1) raised this to **53.6â€¯%**, with a Medium variant reaching **61.6â€¯%** on SWEâ€‘Bench.  
- Designed to **navigate codebases and follow multi-step instructions**, AutoChain-of-Thought prompting works seamlessly within its scaffold.

â¡ï¸ **Conclusion:** Devstral offers state-of-the-art CoT-enhanced reasoning for coding tasks, rivaling proprietary models.

---

### ğŸ’¸ 4. Cost, Licensing & Deployment  
- Licensed under **Apacheâ€¯2.0**, allowing commercial use, modification, and local hosting.  
- Light enough to run on a **single RTXâ€¯4090 GPU or 32â€¯GB RAM Mac**, with quantized support via Ollama, llama.cpp, vLLM, etc.  
- Local inference is private and low-cost; API variants (Small 1.1 & Medium) are priced around $0.1â€“$0.4 per million input tokens.

â¡ï¸ **Conclusion:** Devstral blends high performance with accessible deployment and permissive licensing.

---

### ğŸ§© 5. Summary Table

| Feature                      | Devstral (Small 24B / Medium)              |
|-----------------------------|--------------------------------------------|
| **Context window**          | 128â€¯K tokens                               |
| **CoT & agent support**     | Built-in tool scaffold & multi-step logic |
| **SWEâ€‘Bench Verified**      | 46.8â€¯% â†’ 53.6â€¯% (Small), 61.6â€¯% (Medium)   |
| **Tool integration**        | OpenHands, Ollama, Goose, Continue-ready   |
| **Deployment & license**    | Apacheâ€¯2.0, singleâ€‘GPU, lowâ€‘cost           |

---

### âœ… In summary  
For engineers building **local, autonomous coding agents**, **Devstral** is outstanding:  
- Massive **128â€¯K context** ideal for sprawling codebases,  
- Deep **agent scaffolding** for real-world tooling,  
- Top-tier **CoT reasoning and benchmark scores**,  
- Fully **open-source with commercial licensing**,  
- And highly **efficient on consumer-grade GPUs**.

Itâ€™s a leading open-source agent model for software engineering tasks.

